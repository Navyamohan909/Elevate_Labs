{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flask pyngrok nltk scikit-learn joblib -q"
      ],
      "metadata": {
        "id": "Cs0D6zw2nwYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "import joblib\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from flask import Flask, request, render_template_string\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import threading\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# Define text cleaning function\n",
        "def clean_text_for_prediction(text_input):\n",
        "    text_input = str(text_input).lower()\n",
        "    text_input = ''.join([c for c in text_input if c not in string.punctuation])\n",
        "    tokens = text_input.split()\n",
        "    tokens = [w for w in tokens if w not in stopwords.words('english')]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Load model and vectorizer\n",
        "def load_model_and_vectorizer():\n",
        "    global loaded_model, loaded_vectorizer\n",
        "    model_path = '/content/news_model.pkl'\n",
        "    vectorizer_path = '/content/vectorizer.pkl'\n",
        "\n",
        "    if not os.path.exists(model_path) or not os.path.exists(vectorizer_path):\n",
        "        print(\"Model or vectorizer file not found at specified paths.\")\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            print(\"Please upload 'news_model.pkl' and 'vectorizer.pkl'.\")\n",
        "            uploaded = files.upload()\n",
        "        except ImportError:\n",
        "            print(\"Not in Colab. Ensure files are at /content/.\")\n",
        "            return False\n",
        "\n",
        "    try:\n",
        "        loaded_model = joblib.load(model_path)\n",
        "        loaded_vectorizer = joblib.load(vectorizer_path)\n",
        "        print(\"‚úÖ Model and vectorizer loaded successfully.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading model/vectorizer: {e}\")\n",
        "        return False\n",
        "\n",
        "# Create Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "html_template = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>News Authenticity Checker</title>\n",
        "    <style>\n",
        "        body { font-family: Arial, sans-serif; margin: 40px; background-color: #f4f4f9; }\n",
        "        h1 { text-align: center; color: #333; }\n",
        "        .container { max-width: 600px; margin: 0 auto; padding: 20px; background: white; border-radius: 8px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }\n",
        "        textarea { width: 100%; height: 100px; margin: 10px 0; padding: 10px; }\n",
        "        input[type=submit] { background-color: #4CAF50; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer; }\n",
        "        input[type=submit]:hover { background-color: #45a049; }\n",
        "        .result { margin-top: 20px; font-weight: bold; color: #333; }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <h1>üì∞ News Authenticity Checker</h1>\n",
        "        <form method=\"POST\">\n",
        "            <textarea name=\"news_text\" placeholder=\"Enter news text here\">{{ S_TEXT if S_TEXT else '' }}</textarea>\n",
        "            <input type=\"submit\" value=\"Check Authenticity\">\n",
        "        </form>\n",
        "        {% if PRED_RESULT %}\n",
        "        <div class=\"result\">Prediction: {{ PRED_RESULT }}</div>\n",
        "        {% endif %}\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def home():\n",
        "    print(\"Received request at /\")\n",
        "    prediction_result = None\n",
        "    user_input = None\n",
        "    if request.method == \"POST\":\n",
        "        print(\"Processing POST request\")\n",
        "        news_text = request.form.get(\"news_text\", \"\").strip()\n",
        "        user_input = news_text\n",
        "        if news_text:\n",
        "            try:\n",
        "                cleaned_text = clean_text_for_prediction(news_text)\n",
        "                vectorized_input = loaded_vectorizer.transform([cleaned_text])\n",
        "                pred = loaded_model.predict(vectorized_input)[0]\n",
        "                prediction_result = \"REAL\" if pred == 1 else \"FAKE\"\n",
        "                print(f\"Prediction completed: {prediction_result}\")\n",
        "            except Exception as e:\n",
        "                prediction_result = f\"Error: {e}\"\n",
        "                print(f\"Prediction error: {e}\")\n",
        "    return render_template_string(html_template, PRED_RESULT=prediction_result, S_TEXT=user_input)\n",
        "\n",
        "# Function to run Flask app\n",
        "def run_flask():\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üîÅ Starting Execution...\")\n",
        "    if load_model_and_vectorizer():\n",
        "        # Set ngrok auth token\n",
        "        NGROK_AUTH_TOKEN = \"2xV3q6f39efPkbaVMQ53H5TMafv_5ZckYvEzZnMubgauwFnv9\"\n",
        "        try:\n",
        "            ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "            print(\"‚úÖ Ngrok auth token set successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error setting ngrok auth token: {e}\")\n",
        "            exit(1)\n",
        "\n",
        "        try:\n",
        "            ngrok.kill()  # Clean any old tunnels\n",
        "            print(\"‚úÖ Cleared old ngrok tunnels.\")\n",
        "            public_url = ngrok.connect(5000, bind_tls=True)\n",
        "            print(f\"üåê App is running at: {public_url}\")\n",
        "\n",
        "            # Start Flask in a separate thread to avoid blocking\n",
        "            flask_thread = threading.Thread(target=run_flask)\n",
        "            flask_thread.start()\n",
        "            flask_thread.join()  # Wait for the Flask app to finish\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Could not launch app: {e}\")\n",
        "    else:\n",
        "        print(\"‚ùå Could not load model or vectorizer. Please check file names.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RUefvMYoiCD",
        "outputId": "34a26cf2-a1cf-4c3a-918c-9ce785269060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÅ Starting Execution...\n",
            "‚úÖ Model and vectorizer loaded successfully.\n",
            "‚úÖ Ngrok auth token set successfully.\n",
            "‚úÖ Cleared old ngrok tunnels.\n",
            "üåê App is running at: NgrokTunnel: \"https://4b32-34-16-255-200.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [23/May/2025 14:56:06] \"GET / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received request at /\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/May/2025 14:56:07] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/May/2025 14:56:21] \"POST / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received request at /\n",
            "Processing POST request\n",
            "Prediction completed: REAL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/May/2025 14:56:51] \"POST / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received request at /\n",
            "Processing POST request\n",
            "Prediction completed: FAKE\n"
          ]
        }
      ]
    }
  ]
}